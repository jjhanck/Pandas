{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Business Justification\n",
    " This data was collected in order to train a prediction algorithm to correctly identify handwritten digits from 0 to 9 from the MNIST training set.  The data was sourced from Kaggle’s Digit Recognizer competition at the following site: https://www.kaggle.com/c/digit-recognizer/data.  The objective of the competition is to build a fast and effective process for classifying and identifying handwritten characters using computer image processing, and machine learning. By measuring the percentage correctly predicted from the test set, we can gauge the effectiveness of the algorithm.  Achieving a 95% or above accuracy is considered a success rate. Since Kaggle is an open project competition, it fosters various types of collaboration and algorithm benchmarking, this is a  great way to enhance our Data Science learning.\n",
    "    hand written digit recognition has numerous applications in computer vision.  Banks use automatic cashing of hand written checks, sorting mail by zipcode, and potentially reconstructing shredded files.  Further research into handwritten alphabet recognition has lead to novel advancements such as Google Maps' use of gps and streetview images of actual home address numbers to locate street addresses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Data\n",
    "There are 2 data sets to work with, the first being the training set, and the second, smaller test set. The training set is comprised of 42,000 rows each representing handwritten digits with 784 pixels or 28 pixels squared.  The training set also includes a label for each observation.  The pixel columns are indexed from pixel0 to pixel783 as a minified RGB value; ordinal measures of color between 0 and 255 inclusive.  Because these images are greyscale, all red, green, and blue values are equal to the same ordinal number.  A solid black, for example, would have an (R,G,B) value of (0, 0, 0), and to conserve memory, this value is stored as a singleton pixel equal to (0).  In contrast, white holds a value of (255); and greyscale is an integer value anywhere in this range.  Each row is identified by the first column “label”, which is a nominal integer value, 0 through 9; these are the 10 classes of digits contained in the set.  These labels will be used as class variables for training.  \n",
    "    The test data set is 28,000 rows, with labels omitted, and independent of the the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading the data. Due to the extremely large amount of dimensions involved in this data set, it was decided to reduce the volume of rows to only 1000. This is due to the fact that a logistic regression will perfrom a lot of functions within memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Columns: 785 entries, label to pixel783\n",
      "dtypes: int64(785)\n",
      "memory usage: 6.0 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from __future__ import print_function\n",
    "\n",
    "df = pd.read_csv('data/train_hand.csv', nrows=1000) \n",
    "\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As shown in the data description below, the 1000 row sample of the data does appear to be sufficient as the mean, and standard deviation are very similar to that of Assignement #1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1000.000000\n",
       "mean        4.401000\n",
       "std         2.888692\n",
       "min         0.000000\n",
       "25%         2.000000\n",
       "50%         4.000000\n",
       "75%         7.000000\n",
       "max         9.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'].describe().transpose()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Logistic Regression\n",
    "The logistic regression is designed to help predict a binary outcome on a categorical data set. For the data set used the categories will consist of the general pixel positions of the handwritten letter data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below code is used to get the correct labels for each of the variables of the data set, as well as assure that the X and Y axes are representive of the data model for plotting purposes. A Shufflesplit is also perfromed on the data set, in order to split data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(1000, n_iter=3, test_size=0.2, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "if 'label' in df:\n",
    "    y = df['label'].values\n",
    "    del df['label'] \n",
    "    X = df.values \n",
    "\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n=num_instances,\n",
    "                         n_iter=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below a logistic regression is run with two variations included in order to assure that the randomized sample used in each interation was representitive of the sample. Within the logistic regression the train indices are defined as well as the accuracy scores for each iteration. \n",
    "\n",
    "The two iterations present a 83% and 81.5% respectively. Meaning that the two iterations are fairly similar in nature to one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Iteration 0  ====\n",
      "accuracy 0.83\n",
      "confusion matrix\n",
      " [[23  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 21  0  0  0  0  0  0  1  0]\n",
      " [ 0  0 19  1  0  0  1  0  2  0]\n",
      " [ 0  0  0 16  1  0  0  0  0  0]\n",
      " [ 0  0  0  0 16  0  0  1  1  4]\n",
      " [ 1  0  0  0  0 16  0  0  1  0]\n",
      " [ 1  1  1  0  0  0 17  0  2  0]\n",
      " [ 0  1  0  0  0  0  0  8  0  1]\n",
      " [ 0  2  0  0  1  2  0  0 16  1]\n",
      " [ 0  0  0  0  1  1  0  4  1 14]]\n",
      "====Iteration 1  ====\n",
      "accuracy 0.815\n",
      "confusion matrix\n",
      " [[24  0  0  0  0  0  0  0  0  1]\n",
      " [ 0 18  0  1  0  0  0  0  0  0]\n",
      " [ 0  0 22  1  2  0  0  2  4  0]\n",
      " [ 0  0  0 14  0  0  0  0  1  0]\n",
      " [ 0  0  0  0 16  0  0  0  1  4]\n",
      " [ 0  0  0  2  1  8  1  1  2  0]\n",
      " [ 0  0  0  0  2  0 18  1  1  1]\n",
      " [ 0  1  0  0  1  0  0 16  0  1]\n",
      " [ 0  1  0  0  0  0  0  0  9  3]\n",
      " [ 0  0  0  0  0  0  0  1  0 18]]\n",
      "====Iteration 2  ====\n",
      "accuracy 0.755\n",
      "confusion matrix\n",
      " [[20  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 17  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 22  2  0  0  0  2  1  0]\n",
      " [ 1  2  1 20  0  4  0  0  2  0]\n",
      " [ 0  0  2  0 15  0  1  0  0  4]\n",
      " [ 1  0  1  2  0 10  1  0  1  0]\n",
      " [ 0  0  1  0  2  0 12  0  1  0]\n",
      " [ 0  1  0  0  0  0  0 12  0  6]\n",
      " [ 0  0  0  0  0  5  0  0 10  0]\n",
      " [ 0  0  2  0  1  0  0  0  2 13]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "lr_clf = LogisticRegression(penalty='l2', C=1.0, class_weight=None)\n",
    "\n",
    "iter_num=0\n",
    "for train_indices, test_indices in cv_object: \n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "\n",
    "    lr_clf.fit(X_train,y_train) \n",
    "    y_hat = lr_clf.predict(X_test) \n",
    "\n",
    "    acc = mt.accuracy_score(y_test,y_hat)\n",
    "    conf = mt.confusion_matrix(y_test,y_hat)\n",
    "    print(\"====Iteration\",iter_num,\" ====\")\n",
    "    print(\"accuracy\", acc )\n",
    "    print(\"confusion matrix\\n\",conf)\n",
    "    iter_num+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below logistic regression is the same test with just a shorter code set. The accuracies listed in the output below are also very similar to those we recieved from the previous problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.8    0.835  0.855]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics as mt\n",
    "lr_clf = LogisticRegression(penalty='l2', C=1.0, class_weight=None) \n",
    "from sklearn.cross_validation import cross_val_score\n",
    "accuracies = cross_val_score(lr_clf, X, y=y, cv=cv_object) \n",
    "print(accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a widget that helps one determine the various accuracy percentages given various levels of cost. We can see that the accuracy stays reletively constant, except that the accuracy goes down as the cost is lowered on the slider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.81   0.85   0.815]\n"
     ]
    }
   ],
   "source": [
    "from ipywidgets import widgets as wd\n",
    "\n",
    "def lr_explor(cost):\n",
    "    lr_clf = LogisticRegression(penalty='l2', C=cost, class_weight=None)\n",
    "    accuracies = cross_val_score(lr_clf,X,y=y,cv=cv_object) \n",
    "    print(accuracies)\n",
    "\n",
    "wd.interact(lr_explor,cost=(0.001,5.0,0.05))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Below a standard scaler is run. The standard scaler is designed to standardize features by removing the mean and scaling to unit variance. Due to the fact that this data set has a very large amount of elements the findings from this test will be fairly ambiguous, however it is important to note that the values do step down when moving down the scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.76\n",
      "[[20  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 17  0  0  0  0  0  0  0  0]\n",
      " [ 0  1 22  0  0  0  1  2  1  0]\n",
      " [ 1  0  3 21  0  3  0  2  0  0]\n",
      " [ 0  0  1  2 14  0  0  0  0  5]\n",
      " [ 1  0  2  1  0 11  1  0  0  0]\n",
      " [ 0  0  1  0  2  0 13  0  0  0]\n",
      " [ 0  1  0  0  1  0  0 13  0  4]\n",
      " [ 1  0  0  0  2  4  0  0  8  0]\n",
      " [ 1  0  0  0  3  0  0  1  0 13]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-ff43277980db>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# sort these attributes and spit them out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[0mzip_vars\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlr_clf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# combine attributes\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m \u001b[0mzip_vars\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# sort them by the magnitude of the weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mcoef\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip_vars\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'has weight of'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoef\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m# now print them out\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# scale attributes by the training set\n",
    "scl_obj = StandardScaler()\n",
    "scl_obj.fit(X_train) # find scalings for each column that make this zero mean and unit std\n",
    "# the line of code above only looks at training data to get mean and std and we can use it \n",
    "# to transform new feature data\n",
    "\n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) # apply those means and std to the test set (without snooping at the test set values)\n",
    "\n",
    "# train the model just as before\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.05) # get object, the 'C' value is less (can you guess why??)\n",
    "lr_clf.fit(X_train_scaled,y_train)  # train object\n",
    "\n",
    "y_hat = lr_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf )\n",
    "\n",
    "# sort these attributes and spit them out\n",
    "zip_vars = zip(lr_clf.coef_.T,df.columns) # combine attributes\n",
    "zip_vars.sort(key = lambda t: np.abs(t[0])) # sort them by the magnitude of the weight\n",
    "for coef, name in zip_vars:\n",
    "    print(name, 'has weight of', coef[0]) # now print them out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it is time to plot the dweights to show where the numbers might lie in determination of which attributes are most important when predicting. As stated presviouly this data set is a little odd in determination of variable selection however we can see that the pixels in the middle of the data set, show to a much greater extent where the possible future values may lie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAElCAYAAAD+wXUWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x107c4828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "\n",
    "weights = pd.Series(lr_clf.coef_[0],index=df.columns)\n",
    "weights.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below a pipeline is used to help to a greater extent which values are the largest deterininents. A pipline essentially applies a list of transforms along with a final estimator. The final estimator only needs to implement fit. From this we can determine which of the variables is most vital for model creation. As shown in the output the values toward the middle of the pixel scale appear to be the most likely determininents which is to be expected as most of the items would be drawn centered arond the middle of the box."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Anaconda2\\lib\\site-packages\\sklearn\\utils\\validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAElCAYAAAD+wXUWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10aeca58>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "std_scl = StandardScaler()\n",
    "lr_clf = LogisticRegression(penalty='l2', C=0.05) \n",
    "\n",
    "piped_object = Pipeline([('scale', std_scl), ('logit_model', lr_clf)])\n",
    "\n",
    "for iter_num, (train_indices, test_indices) in enumerate(cv_object):\n",
    "    piped_object.fit(X[train_indices],y[train_indices])  \n",
    "    \n",
    "trained_model_from_pipeline = piped_object.named_steps['logit_model']\n",
    "\n",
    "weights = pd.Series(trained_model_from_pipeline.coef_[0],index=df.columns)\n",
    "weights.plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
   {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Use Pandas to import as a data frame\n",
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('data/train.csv')\n",
    "test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ShuffleSplit(42000, n_iter=3, test_size=0.2, random_state=None)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import ShuffleSplit\n",
    "\n",
    "# Create a training set and a cross validation set using 50% of the data for cross validation\n",
    "\n",
    "# dftrain, dfcross = train_test_split(train, test_size = 0.5)\n",
    "\n",
    "# Set X and y\n",
    "X = train.values\n",
    "y = train['label'].values\n",
    "\n",
    "num_cv_iterations = 3\n",
    "num_instances = len(y)\n",
    "cv_object = ShuffleSplit(n=num_instances,\n",
    "                         n_iter=num_cv_iterations,\n",
    "                         test_size  = 0.2)\n",
    "                         \n",
    "print(cv_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for Null values or duplicate rows...  None found\n"
     ]
    }
   ],
   "source": [
    "# Check Data \n",
    "\n",
    "print \"Checking for Null values or duplicate rows... \", \n",
    "if train.isnull().all().any() or train.duplicated().all(): \n",
    "    print('error in data')\n",
    "else:\n",
    "    print('None found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/majickdave/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Users/majickdave/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:420: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# okay, so run through the cross validation loop and set the training and testing variable for one single iteration\n",
    "for train_indices, test_indices in cv_object: \n",
    "    # I will create new variables here so that it is more obvious what \n",
    "    # the code is doing (you can compact this syntax and avoid duplicating memory,\n",
    "    # but it makes this code less readable)\n",
    "    X_train = X[train_indices]\n",
    "    y_train = y[train_indices]\n",
    "    \n",
    "    X_test = X[test_indices]\n",
    "    y_test = y[test_indices]\n",
    "    \n",
    "X_train_scaled = scl_obj.transform(X_train) # apply to training\n",
    "X_test_scaled = scl_obj.transform(X_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('accuracy:', 0.97928571428571431)\n",
      "[[847   0   4   0   0   0   0   0   0   0]\n",
      " [  1 951   8   0   0   0   0   0   0   0]\n",
      " [  6  13 823   1   8   0   0   0   0   0]\n",
      " [  3   2   7 845   3   0   0   0   0   0]\n",
      " [  0   4   4   1 754   7   0   2   0   0]\n",
      " [  1   0   0   3   5 739   8   1   0   0]\n",
      " [  0   0   0   0   5  15 769   1   0   0]\n",
      " [  0   0   0   0   4   0   1 917  10   2]\n",
      " [  0   0   0   0   0   2   9   3 772  16]\n",
      " [  0   0   0   0   2   0   2   2   8 809]]\n"
     ]
    }
   ],
   "source": [
    "# lets investigate SVMs on the data and play with the parameters and kernels\n",
    "from sklearn.svm import SVC\n",
    "from sklearn import metrics as mt\n",
    "\n",
    "\n",
    "# train the model just as before\n",
    "svm_clf = SVC(C=0.5, kernel='linear', degree=3, gamma='auto') # get object\n",
    "svm_clf.fit(X_train_scaled, y_train)  # train object\n",
    "\n",
    "y_hat = svm_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "print('accuracy:', acc )\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \n",
    "# Split Training Data in half to allow cross validation\n",
    "# The method,train_test_split divides our data set into \n",
    "# training and test data through randomization\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.5, random_state=28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X and y have incompatible shapes.\nX has 33600 samples, but y has 21000.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-837f95949d4e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m       verbose=False, max_iter=1000, decision_function_shape=None, random_state=None)\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mnsvc_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# train object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0my_hat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test_scaled\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get test set precitions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/majickdave/anaconda/lib/python2.7/site-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    160\u001b[0m             raise ValueError(\"X and y have incompatible shapes.\\n\" +\n\u001b[1;32m    161\u001b[0m                              \u001b[0;34m\"X has %s samples, but y has %s.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                              (X.shape[0], y.shape[0]))\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"precomputed\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X and y have incompatible shapes.\nX has 33600 samples, but y has 21000."
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "import sklearn as sk\n",
    "import numpy as np\n",
    "#  default settings sklearn.svm.LinearSVC(penalty='l2', loss='squared_hinge', dual=True, tol=0.0001, \n",
    "#  C=1.0, multi_class='ovr', fit_intercept=True, \n",
    "#  intercept_scaling=1, class_weight=None, verbose=0, random_state=None, max_iter=1000)[source]\n",
    "nsvc_clf = sk.svm.NuSVC(nu=0.5, kernel='rbf', degree=3, gamma='auto', coef0=0.0, shrinking=True, \n",
    "      probability=False, tol=0.001, cache_size=200, class_weight=None, \n",
    "      verbose=False, max_iter=1000, decision_function_shape=None, random_state=None)\n",
    "\n",
    "nsvc_clf.fit(X_train_scaled, y_train)  # train object\n",
    "\n",
    "y_hat = svm_clf.predict(X_test_scaled) # get test set precitions\n",
    "\n",
    "acc = mt.accuracy_score(y_test,y_hat)\n",
    "conf = mt.confusion_matrix(y_test,y_hat)\n",
    "\n",
    "print(time.time()-start)\n",
    "print('accuracy:', acc )\n",
    "print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# These are the number of support vectors\n",
    "svm_clf.n_support_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# look at the support vectors\n",
    "print(svm_clf.support_vectors_.shape)\n",
    "print(svm_clf.support_.shape)\n",
    "print(svm_clf.n_support_ )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if using linear kernel, these make sense to look at (not otherwise, why?)\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "print(svm_clf.coef_)\n",
    "weights = pd.Series(svm_clf.coef_[0],index=train.columns)\n",
    "\n",
    "sns = weights.plot(color = \"purple\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The plot above shows a high concentration of vectors in pixels 300-500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now let's do some different analysis with the SVM and look at the instances that were chosen as support vectors\n",
    "\n",
    "# now lets look at the support for the vectors and see if we they are indicative of anything\n",
    "# grabe the rows that were selected as support vectors (these are usually instances that are hard to classify)\n",
    "\n",
    "# make a dataframe of the training data\n",
    "df_tested_on = train.iloc[train_indices] # saved from above, the indices chosen for training\n",
    "# now get the support vectors from the trained model\n",
    "df_support = df_tested_on.loc[svm_clf.support_,:]\n",
    "\n",
    "df_support['label'] = y[svm_clf.support_] # add back in the 'Survived' Column to the pandas dataframe\n",
    "train['label'] = y # also add it back in for the original data\n",
    "df_support.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# now lets see the statistics of these attributes\n",
    "from pandas.tools.plotting import boxplot\n",
    "\n",
    "# group the original data and the support vectors\n",
    "df_grouped_support = df_support.groupby(['label'])\n",
    "df_grouped = train.groupby(['label'])\n",
    "\n",
    "# plot KDE of Different variables\n",
    "vars_to_plot = []\n",
    "for i in range(len(df_grouped)):\n",
    "    if i > 300 and i < 500:\n",
    "        vars_to_plot.append(df_grouped.columns[i])\n",
    "\n",
    "for v in vars_to_plot:\n",
    "    sns = plt.figure(figsize=(10,4))\n",
    "    # plot support vector stats\n",
    "    plt.subplot(1,2,1)\n",
    "    ax = df_grouped_support[v].plot.kde() \n",
    "    plt.legend(['pixel300','pixel450'])\n",
    "    plt.title(v+' (Instances chosen as Support Vectors)')\n",
    "    \n",
    "    # plot original distributions\n",
    "    plt.subplot(1,2,2)\n",
    "    ax = df_grouped[v].plot.kde() \n",
    "    plt.legend(['pixel300','pixel450'])\n",
    "    plt.title(v+' (Original)')\n",
    "\n"
   ]
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}

  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import NuSVC\n",
    "\n",
    "clf = NuSVC()\n",
    "clf.fit(X, y)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
